{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, pandas\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"incidents.json\", 'r') as incident_json:\n",
    "    incidents = json.load(incident_json)\n",
    "    \n",
    "with open(\"featuredata.json\", 'r') as feature_json:\n",
    "    featuredata = json.load(feature_json)\n",
    "    \n",
    "with open(\"reducedwaydata.json\", \"r\") as waydata_json:\n",
    "    waydata = json.load(waydata_json)\n",
    "    \n",
    "with open(\"node_data.json\", \"r\") as nodedata_json:\n",
    "    nodedata = json.load(nodedata_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def in_bounding_box(polyline, point, fuzz = 0.0001):\n",
    "    \"\"\"\n",
    "    Check the first and last points in the polyline and check if the point lies within this box.\n",
    "    Note: this will not work properly for curvy streets.\n",
    "    \"\"\"\n",
    "    originating_point = polyline[0]\n",
    "    last_point = polyline[-1]\n",
    "    lat = float(point['lat'])\n",
    "    lon = float(point['lon'])\n",
    "    \n",
    "    min_lat = min(float(originating_point['lat']), float(last_point['lat']))\n",
    "    max_lat = max(float(originating_point['lat']), float(last_point['lat']))\n",
    "    min_lon = min(float(originating_point['lon']), float(last_point['lon']))\n",
    "    max_lon = max(float(originating_point['lon']), float(last_point['lon']))\n",
    "    \n",
    "    # 0.0001 degree is approx 10 metres.\n",
    "    if (lat < min_lat - fuzz) or (lat > max_lat + fuzz):\n",
    "        return False\n",
    "    if (lon < min_lon - fuzz) or (lon > max_lon + fuzz):\n",
    "        return False\n",
    "    \n",
    "    # If we are here it is in a reasonable box around the two points!\n",
    "    return True\n",
    "\n",
    "polyline = [\n",
    "        {\n",
    "            \"lat\": 0.0,\n",
    "            \"lon\": 0.0,\n",
    "            },\n",
    "        {\n",
    "            \"lat\": 0.1,\n",
    "            \"lon\": 0.1,\n",
    "            }\n",
    "    ]\n",
    "\n",
    "point = {\"lat\": 0.00005,\n",
    "        \"lon\": 0.0}\n",
    "true_point = {\"lat\": 0.05,\n",
    "             \"lon\":0.05}\n",
    "false_point = {\"lat\": -0.005,\n",
    "        \"lon\": 0.0}\n",
    "print(in_bounding_box(polyline, point))\n",
    "print(in_bounding_box(polyline, true_point))\n",
    "print(in_bounding_box(polyline, false_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def point_is_on_line(point_0, point_1, point_2, fuzz = 0.0001):\n",
    "    \"\"\"\n",
    "    Calculate if a point is within 5m of perpendicular distance of a line.\n",
    "    based on http://mathworld.wolfram.com/Point-LineDistance2-Dimensional.html\n",
    "    \"\"\"\n",
    "    # We have three points: point 0 is the one we want to know the distance of.\n",
    "    # Points 1 and 2 are the line that we'll compare to.\n",
    "    # Ignore the fact that the Earth is a sphere.\n",
    "    x0 = float(point_0[\"lon\"])\n",
    "    y0 = float(point_0[\"lat\"])\n",
    "    x1 = float(point_1[\"lon\"])\n",
    "    y1 = float(point_1[\"lat\"])\n",
    "    x2 = float(point_2[\"lon\"])\n",
    "    y2 = float(point_2[\"lat\"])\n",
    "    \n",
    "    numerator = abs((x2 - x1)*(y1 - y0) - (x1 - x0)*(y2 - y1))\n",
    "    denominator = sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "    try:\n",
    "        d = numerator/denominator\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Zero Division error.\")\n",
    "        return False\n",
    "    \n",
    "    if d > fuzz:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "point_1 = {\n",
    "    \"lat\": 0.0,\n",
    "    \"lon\": 0.0\n",
    "}\n",
    "point_2 = {\n",
    "    \"lat\": 0.1,\n",
    "    \"lon\": 0.1\n",
    "}\n",
    "\n",
    "point_0_true = {\n",
    "    \"lat\": 0.05005,\n",
    "    \"lon\": 0.05\n",
    "    }\n",
    "point_0_false = {\n",
    "    \"lat\": 0.0505,\n",
    "    \"lon\": 0.05\n",
    "    }\n",
    "\n",
    "print(point_is_on_line(point_0_true, point_1, point_2))\n",
    "print(point_is_on_line(point_0_false, point_1, point_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def point_is_on_polyline(polyline, point, fuzz = 0.0001):\n",
    "    \"\"\"\n",
    "    Function to run through a polyline and tell if a point is on the polyline.\n",
    "    \"\"\"\n",
    "    # First step - establish is point is in bounding range of polyline\n",
    "    # Note that this might result in fuckups for curvy streets!\n",
    "    if not in_bounding_box(polyline, point, fuzz):\n",
    "        return False\n",
    "    \n",
    "    # If point is in box, then check point pairs and see if point is within 5 metres\n",
    "    number_of_point_pairs = len(polyline) - 1\n",
    "    for i in range(number_of_point_pairs):\n",
    "        point_1 = polyline[i]\n",
    "        point_2 = polyline[i+1]\n",
    "        if point_is_on_line(point, point_1, point_2, fuzz):\n",
    "            return True\n",
    "        \n",
    "    # If we got here, it wasn't close enough to the street.\n",
    "    return False\n",
    "\n",
    "polyline = {\"points\": [\n",
    "        {\n",
    "            \"lat\": 0.0,\n",
    "            \"lon\": 0.0,\n",
    "        },\n",
    "        {\n",
    "            \"lat\": 0.075,\n",
    "            \"lon\": 0.075\n",
    "        },\n",
    "        {\n",
    "            \"lat\": 0.1,\n",
    "            \"lon\": 0.1\n",
    "        }\n",
    "    ]}\n",
    "\n",
    "true_point = {\n",
    "    \"lat\": 0.05,\n",
    "    \"lon\": 0.05\n",
    "}\n",
    "false_point = {\n",
    "    \"lat\": 0.2,\n",
    "    \"lon\": 0.075\n",
    "}\n",
    "print(point_is_on_polyline(polyline['points'], true_point))\n",
    "print(point_is_on_polyline(polyline['points'], false_point))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping assaults onto streets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lon': 151.21479, 'lat': -33.89239}\n",
      "{'lon': 151.20984, 'lat': -33.8677}\n",
      "{'lon': 151.2191, 'lat': -33.872671}\n",
      "{'lon': 151.22019, 'lat': -33.87026}\n",
      "{'lon': 151.215001, 'lat': -33.88007}\n",
      "{'lon': 151.206701, 'lat': -33.882432}\n",
      "{'lon': 151.22451, 'lat': -33.87519}\n",
      "{'lon': 151.213056, 'lat': -33.863096}\n",
      "{'lon': 151.212542, 'lat': -33.87454}\n",
      "{'lon': 151.207925, 'lat': -33.856479}\n",
      "{'lon': 151.17502, 'lat': -33.87567}\n",
      "{'lon': 151.22088, 'lat': -33.87502}\n",
      "{'lon': 151.20743, 'lat': -33.87809}\n",
      "{'lon': 151.20444, 'lat': -33.88283}\n",
      "{'lon': 151.21036, 'lat': -33.863495}\n",
      "{'lon': 151.20849, 'lat': -33.86097}\n",
      "{'lon': 151.207695, 'lat': -33.896275}\n",
      "{'lon': 151.20849, 'lat': -33.86097}\n",
      "{'lon': 151.20849, 'lat': -33.86097}\n",
      "{'lon': 151.202749, 'lat': -33.877137}\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for incident in incidents:\n",
    "    counter +=1\n",
    "    print(incident)\n",
    "    if counter == 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'lat': '-33.87224', 'lon': '151.19845'}, {'lat': '-33.87234', 'lon': '151.19852'}, {'lat': '-33.87266', 'lon': '151.19877'}, {'lat': '-33.87272', 'lon': '151.19881'}]\n",
      "[{'lat': '-33.87147', 'lon': '151.23026'}, {'lat': '-33.87139', 'lon': '151.23071'}, {'lat': '-33.87124', 'lon': '151.23092'}]\n",
      "[{'lat': '-33.89995', 'lon': '151.18582'}, {'lat': '-33.89997', 'lon': '151.18591'}, {'lat': '-33.90003', 'lon': '151.18589'}, {'lat': '-33.90012', 'lon': '151.18587'}, {'lat': '-33.9002', 'lon': '151.1858'}, {'lat': '-33.90023', 'lon': '151.18573'}]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for way in waydata.keys():\n",
    "    counter += 1\n",
    "    print(waydata[way]['points'])\n",
    "    if counter == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Division error.\n"
     ]
    }
   ],
   "source": [
    "# Our goal is to loop through all the offence locations.\n",
    "# If they lie on a way, mark that way with an offence.\n",
    "# If not go through them all.\n",
    "counter = 0\n",
    "for incident in incidents:\n",
    "    counter += 1\n",
    "    if counter == 10:\n",
    "        break\n",
    "        \n",
    "    for way in waydata.keys():\n",
    "        if point_is_on_polyline(waydata[way]['points'], incident):\n",
    "            if \"incidents\" not in waydata[way].keys():\n",
    "                waydata[way]['incidents'] = 1\n",
    "            else:\n",
    "                waydata[way]['incidents'] += 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yep': 2}\n"
     ]
    }
   ],
   "source": [
    "# quick test...\n",
    "some_dict = dict()\n",
    "if \"yep\" not in some_dict.keys():\n",
    "    some_dict[\"yep\"] = 1\n",
    "some_dict[\"yep\"] += 1\n",
    "print(some_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for way in waydata.keys():\n",
    "    if \"incidents\" in waydata[way].keys():\n",
    "        print(waydata[way]['incidents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n"
     ]
    }
   ],
   "source": [
    "with open(\"reducedwaydata.json\", \"r\") as waydata_json:\n",
    "    waydata = json.load(waydata_json)\n",
    "    \n",
    "# Our goal is to loop through all the offence locations.\n",
    "# If they lie on a way, mark that way with an offence.\n",
    "# If not go through them all.\n",
    "for incident in incidents:\n",
    "        \n",
    "    for way in waydata.keys():\n",
    "        if point_is_on_polyline(waydata[way]['points'], incident):\n",
    "            if \"incidents\" not in waydata[way].keys():\n",
    "                waydata[way]['incidents'] = 1\n",
    "            else:\n",
    "                waydata[way]['incidents'] += 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     incidents                        name\n",
      "154        130                 Cahill Walk\n",
      "130        122           Darlinghurst Road\n",
      "379        108              Kellett Street\n",
      "56          89                 Park Street\n",
      "444         64                        path\n",
      "681         51                        path\n",
      "198         49               Bourke Street\n",
      "52          47               Druitt Street\n",
      "128         44       Liverpool St Cycleway\n",
      "257         43                Mount Street\n",
      "753         43               George Street\n",
      "192         41               Oxford Street\n",
      "816         38                        path\n",
      "205         38              College Street\n",
      "880         36               Bourke Street\n",
      "72          34                        path\n",
      "688         34  Western Distributor Onramp\n",
      "182         33                        path\n",
      "550         32             Victoria Street\n",
      "189         31               Oxford Street\n",
      "227         30            Glebe Point Road\n",
      "605         30                Martin Place\n",
      "930         28              Redfern Street\n",
      "129         26                        path\n",
      "339         26            Cathedral Street\n",
      "134         26                 Pier Street\n",
      "25          25             Goulburn Street\n",
      "396         25              MacLeay Street\n",
      "516         24      George Street Cycleway\n",
      "555         24              Central Street\n",
      "..         ...                         ...\n",
      "635          1           Experiment Street\n",
      "293          1        South Dowling Street\n",
      "289          1                        path\n",
      "268          1             Park Road North\n",
      "686          1                 Lander Lane\n",
      "270          1                 Fleet Steps\n",
      "271          1              Marshal Street\n",
      "697          1               Regent Street\n",
      "696          1               Garden Street\n",
      "273          1                Neild Avenue\n",
      "693          1              Stephen Street\n",
      "691          1               Cooper Street\n",
      "690          1        Victoria Park Parade\n",
      "689          1               Bridge Street\n",
      "275          1              William Street\n",
      "687          1            Macquarie Street\n",
      "276          1                        path\n",
      "671          1            Clarendon Street\n",
      "277          1           Wellington Street\n",
      "683          1             Buckland Street\n",
      "682          1                 King Street\n",
      "278          1                 Eddy Avenue\n",
      "680          1                  Epsom Road\n",
      "679          1    Little Buckingham Street\n",
      "279          1            Castlereagh Lane\n",
      "676          1              Chelsea Street\n",
      "674          1                 Cotter Lane\n",
      "285          1                  Hayes Road\n",
      "286          1                        path\n",
      "0            1              Harbour Street\n",
      "\n",
      "[992 rows x 2 columns]\n",
      "4863\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "crime_streets = list()\n",
    "for way in waydata.keys():\n",
    "    if \"incidents\" in waydata[way].keys():\n",
    "        \n",
    "        crime_dict = dict()\n",
    "        try:\n",
    "            crime_dict['name'] = waydata[way]['name']\n",
    "        except:\n",
    "            crime_dict['name'] = 'path'\n",
    "        crime_dict['incidents'] = waydata[way]['incidents']\n",
    "        crime_streets.append(crime_dict)\n",
    "        \n",
    "df_crimestreets = pd.DataFrame(crime_streets)\n",
    "print(df_crimestreets.sort_values('incidents', ascending = False))\n",
    "print(df_crimestreets['incidents'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Non-assault feature allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(featuredata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bar', 'shop', 'place_of_worship', 'restaurant', 'taxi', 'drinking_water', 'fast_food', 'hostel', 'atm', 'hospital', 'parking', 'pub', 'police', 'nightclub', 'bus_stop'}\n"
     ]
    }
   ],
   "source": [
    "featureset = set()\n",
    "\n",
    "for key in featuredata.keys():\n",
    "    counter += 1\n",
    "    featureset.add(featuredata[key][\"feature\"])\n",
    "\n",
    "print(featureset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 0.0001 approx 10 m\n",
    "# 0.001 approx 100 m\n",
    "# 0.01 approx 1km\n",
    "\n",
    "# We're assuming that these features has a range at which they're important... \n",
    "# This is not a great way to approach this, but it'll work as a first run...\n",
    "featuresetfuzz = {\n",
    "    \"bar\": 0.001,\n",
    "    \"shop\": 0.001,\n",
    "    \"place_of_worship\": 0.0005,\n",
    "    \"restaurant\": 0.0005,\n",
    "    \"taxi\": 0.0001,\n",
    "    \"drinking_water\": 0.0001,\n",
    "    \"fast_food\": 0.0005,\n",
    "    \"hostel\": 0.005,\n",
    "    \"atm\": 0.005,\n",
    "    \"hospital\": 0.001,\n",
    "    \"parking\": 0.001,\n",
    "    \"pub\": 0.001,\n",
    "    \"police\": 0.001,\n",
    "    \"nightclub\": 0.005,\n",
    "    \"bus_stop\": 0.0001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "with open(\"reducedwaydata.json\", \"r\") as waydata_json:\n",
    "    waydata = json.load(waydata_json)\n",
    "\n",
    "for feature in featuredata.keys():\n",
    "    feature_type = featuredata[feature][\"feature\"]\n",
    "    counter += 1    \n",
    "    for way in waydata.keys():\n",
    "        if point_is_on_polyline(waydata[way]['points'], featuredata[feature], featuresetfuzz[feature_type]):\n",
    "            if feature_type not in waydata[way].keys():\n",
    "                waydata[way][feature_type] = 1\n",
    "            else:\n",
    "                waydata[way][feature_type] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"feature_laden_ways_data.json\", 'w') as f:\n",
    "    json.dump(waydata, f, indent = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n",
      "Zero Division error.\n"
     ]
    }
   ],
   "source": [
    "# Ascribe hourly incident data\n",
    "with open(\"feature_laden_ways_data.json\", \"r\") as waydata_json:\n",
    "    waydata = json.load(waydata_json)\n",
    "    \n",
    "# Our goal is to loop through all the offence locations.\n",
    "# If they lie on a way, mark that way with an offence.\n",
    "# If not go through them all.\n",
    "for i in range(24):\n",
    "    with open(\"{0}_incident.json\".format(i), 'r') as incident_json:\n",
    "        incidents = json.load(incident_json)\n",
    "    for incident in incidents:\n",
    "        for way in waydata.keys():\n",
    "            if point_is_on_polyline(waydata[way]['points'], incident):\n",
    "                if \"incident_{0}\".format(i) not in waydata[way].keys():\n",
    "                    waydata[way][\"incident_{0}\".format(i)] = 1\n",
    "                else:\n",
    "                    waydata[way][\"incident_{0}\".format(i)] += 1\n",
    "                break\n",
    "                \n",
    "with open(\"hourly_assaults_feature_laden_ways_data.json\", 'w') as f:\n",
    "    json.dump(waydata, f, indent = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           atm  bar  bus_stop  drinking_water  fast_food  hospital  hostel  \\\n",
      "100183506    1    0         0               0          0         0       3   \n",
      "100183507    1    0         0               0          1         0       8   \n",
      "100183508    1    0         0               0          0         0       1   \n",
      "100183509    0    0         0               0          0         0       0   \n",
      "100183510    0    1         0               0          0         0       0   \n",
      "\n",
      "           incident_0  incident_1  incident_10  ...                     name  \\\n",
      "100183506           0           0            0  ...                        0   \n",
      "100183507           0           0            0  ...                        0   \n",
      "100183508           0           0            0  ...                        0   \n",
      "100183509           0           0            0  ...   Bourke Street Cycleway   \n",
      "100183510           0           0            0  ...                        0   \n",
      "\n",
      "           nightclub  parking  place_of_worship  \\\n",
      "100183506          0        0                 0   \n",
      "100183507          1        0                 0   \n",
      "100183508          0        0                 0   \n",
      "100183509          0        0                 0   \n",
      "100183510          0        0                 0   \n",
      "\n",
      "                                                      points  police  pub  \\\n",
      "100183506  [{'lon': '151.21764', 'lat': '-33.87626'}, {'l...       0    0   \n",
      "100183507  [{'lon': '151.21792', 'lat': '-33.8749'}, {'lo...       0    0   \n",
      "100183508  [{'lon': '151.21693', 'lat': '-33.87987'}, {'l...       0    4   \n",
      "100183509  [{'lon': '151.2132', 'lat': '-33.89682'}, {'lo...       0    0   \n",
      "100183510  [{'lon': '151.2166', 'lat': '-33.88118'}, {'lo...       0    6   \n",
      "\n",
      "           restaurant  shop  taxi  \n",
      "100183506           0     0     0  \n",
      "100183507           0     1     0  \n",
      "100183508           3     0     0  \n",
      "100183509           0     2     0  \n",
      "100183510           0     4     0  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "df_final_dataset = pd.DataFrame(waydata).transpose().fillna(0)\n",
    "print(df_final_dataset.head())\n",
    "df_final_dataset.to_csv(\"final_predictive_datset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate predictions for the safety of any particular street\n",
    "from sklearn import tree\n",
    "\n",
    "for i in range(24):\n",
    "    X = df_final_dataset[list(featureset)]\n",
    "    y = df_final_dataset[\"incident_{0}\".format(i)]\n",
    "    clf = tree.DecisionTreeRegressor()\n",
    "    clf = clf.fit(X, y)\n",
    "    df_final_dataset[\"incident_{0}_predict\".format(i)] = clf.predict(df_final_dataset[list(featureset)])\n",
    "    low_threshold = df_final_dataset[df_final_dataset[\"incident_{0}_predict\".format(i)] > 0][\"incident_{0}_predict\".format(i)].median()\n",
    "    high_threshold = df_final_dataset[df_final_dataset[\"incident_{0}_predict\".format(i)] > 0][\"incident_{0}_predict\".format(i)].mean()\n",
    "    df_final_dataset[\"{0}\".format(i)] = df_final_dataset[\"incident_{0}_predict\".format(i)].apply(lambda x: 1 if x > low_threshold else 0)\n",
    "    df_final_dataset[\"{0}\".format(i)] = df_final_dataset[df_final_dataset[\"incident_{0}_predict\".format(i)] > low_threshold][\"incident_{0}_predict\".format(i)].apply(lambda x: 2 if x > high_threshold else 1)\n",
    "df_final_dataset.to_csv(\"prediction_datasets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      points  \\\n",
      "100183506  [{'lon': '151.21764', 'lat': '-33.87626'}, {'l...   \n",
      "100183507  [{'lon': '151.21792', 'lat': '-33.8749'}, {'lo...   \n",
      "100183508  [{'lon': '151.21693', 'lat': '-33.87987'}, {'l...   \n",
      "100183509  [{'lon': '151.2132', 'lat': '-33.89682'}, {'lo...   \n",
      "100183510  [{'lon': '151.2166', 'lat': '-33.88118'}, {'lo...   \n",
      "\n",
      "                             name    0    1    2    3    4    5    6    7  \\\n",
      "100183506                       0  2.0  2.0  1.0  1.0  2.0  2.0  NaN  NaN   \n",
      "100183507                       0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "100183508                       0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "100183509  Bourke Street Cycleway  NaN  NaN  1.0  NaN  NaN  2.0  NaN  NaN   \n",
      "100183510                       0  2.0  2.0  2.0  2.0  NaN  2.0  2.0  2.0   \n",
      "\n",
      "          ...   14  15   16   17   18   19   20   21   22   23  \n",
      "100183506 ...  NaN NaN  NaN  2.0  NaN  NaN  2.0  2.0  2.0  1.0  \n",
      "100183507 ...  NaN NaN  NaN  2.0  NaN  NaN  2.0  2.0  2.0  2.0  \n",
      "100183508 ...  NaN NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "100183509 ...  NaN NaN  NaN  1.0  1.0  NaN  1.0  NaN  1.0  1.0  \n",
      "100183510 ...  NaN NaN  2.0  2.0  2.0  2.0  2.0  2.0  2.0  2.0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# This is the final dataset that will be displayed on the website.\n",
    "# Note that this is a horrible way to present this data for a web platform, and it will make any \n",
    "# web developer cry.\n",
    "\n",
    "import json\n",
    "\n",
    "relevant_columns = [\"points\",\"name\"]\n",
    "for i in range(24):\n",
    "    relevant_columns.append(\"{0}\".format(i))\n",
    "df_json_output = df_final_dataset[(relevant_columns)]\n",
    "print(df_json_output.head())\n",
    "df_json_output.to_json(\"street_predictions.json\", orient=\"records\")\n",
    "with open(\"street_predictions.json\", 'r') as predictions_json:\n",
    "    street_predictions = json.load(predictions_json)\n",
    "with open(\"street_predictions.json\", 'w') as predictions_json:\n",
    "    json.dump(street_predictions, predictions_json, indent = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
